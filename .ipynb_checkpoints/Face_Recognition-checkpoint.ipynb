{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Face Recognition Code using ageitgey's face detection library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 43, Left: 86, Bottom: 157, Right: 200\n"
     ]
    }
   ],
   "source": [
    "#This code is borrowed from ageitgey's github\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file('/Users/Scott/Documents/DSI6/FaceRecognition/littlescott.jpg')\n",
    "\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "image = face_recognition.load_image_file(\"/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/scott.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(142, 617, 409, 349)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bottom_lip': [(555, 319),\n",
       "   (536, 344),\n",
       "   (513, 357),\n",
       "   (495, 360),\n",
       "   (477, 359),\n",
       "   (453, 348),\n",
       "   (433, 323),\n",
       "   (439, 324),\n",
       "   (478, 343),\n",
       "   (495, 345),\n",
       "   (513, 342),\n",
       "   (549, 321)],\n",
       "  'chin': [(369, 220),\n",
       "   (372, 254),\n",
       "   (378, 289),\n",
       "   (384, 322),\n",
       "   (395, 353),\n",
       "   (414, 382),\n",
       "   (437, 407),\n",
       "   (464, 424),\n",
       "   (495, 428),\n",
       "   (527, 420),\n",
       "   (552, 399),\n",
       "   (576, 372),\n",
       "   (594, 344),\n",
       "   (604, 314),\n",
       "   (610, 282),\n",
       "   (613, 250),\n",
       "   (615, 219)],\n",
       "  'left_eye': [(424, 217),\n",
       "   (437, 210),\n",
       "   (450, 210),\n",
       "   (464, 217),\n",
       "   (451, 218),\n",
       "   (437, 219)],\n",
       "  'left_eyebrow': [(397, 209), (411, 191), (433, 183), (457, 184), (479, 190)],\n",
       "  'nose_bridge': [(496, 210), (497, 231), (497, 252), (497, 273)],\n",
       "  'nose_tip': [(465, 285), (480, 289), (496, 293), (511, 288), (526, 284)],\n",
       "  'right_eye': [(528, 217),\n",
       "   (542, 209),\n",
       "   (555, 210),\n",
       "   (568, 217),\n",
       "   (555, 218),\n",
       "   (541, 218)],\n",
       "  'right_eyebrow': [(514, 189),\n",
       "   (536, 182),\n",
       "   (558, 182),\n",
       "   (579, 190),\n",
       "   (592, 206)],\n",
       "  'top_lip': [(433, 323),\n",
       "   (454, 314),\n",
       "   (478, 312),\n",
       "   (495, 314),\n",
       "   (512, 311),\n",
       "   (535, 312),\n",
       "   (555, 319),\n",
       "   (549, 321),\n",
       "   (512, 318),\n",
       "   (495, 321),\n",
       "   (478, 319),\n",
       "   (439, 324)]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_image = face_recognition.load_image_file(\"/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/scott.jpg\")\n",
    "unknown_image = face_recognition.load_image_file(\"/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/other_redhead.jpg\")\n",
    "\n",
    "obama_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([obama_encoding], unknown_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the unknown face a picture of Scott? True\n",
      "Is the unknown face a picture of another redhead? False\n",
      "Is the unknown face a new person that we've never seen before? False\n"
     ]
    }
   ],
   "source": [
    "# Load the jpg files into numpy arrays\n",
    "scott_image = face_recognition.load_image_file(\"/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/scott.jpg\")\n",
    "other_redhead = face_recognition.load_image_file(\"/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/other_redhead.jpg\")\n",
    "unknown_image = face_recognition.load_image_file('/Users/Scott/Documents/DSI6/My Projects /FaceRecognition/scott2.jpg')\n",
    "\n",
    "# Get the face encodings for each face in each image file\n",
    "# Since there could be more than one face in each image, it returns a list of encodings.\n",
    "# But since I know each image only has one face, I only care about the first encoding in each image, so I grab index 0.\n",
    "scott_face_encoding = face_recognition.face_encodings(scott_image)[0]\n",
    "other_redhead_encoding = face_recognition.face_encodings(other_redhead)[0]\n",
    "unknown_face_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "known_faces = [\n",
    "    scott_face_encoding,\n",
    "    other_redhead_encoding\n",
    "]\n",
    "\n",
    "# results is an array of True/False telling if the unknown face matched anyone in the known_faces array\n",
    "results = face_recognition.compare_faces(known_faces, unknown_face_encoding)\n",
    "\n",
    "print(\"Is the unknown face a picture of Scott? {}\".format(results[0]))\n",
    "print(\"Is the unknown face a picture of another redhead? {}\".format(results[1]))\n",
    "print(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### So we see that this algorithm was able to locate the unknown picture as my face and identify that its not the other red, which is super cool. It was able to do this many times in a row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
